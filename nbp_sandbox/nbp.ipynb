{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import stim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DEM_Matrices:\n",
    "    check_matrix: torch.Tensor\n",
    "    logical_matrix: torch.Tensor\n",
    "    llrs: torch.Tensor\n",
    "\n",
    "def DEM_to_matrices(DEM: stim.DetectorErrorModel) -> DEM_Matrices:\n",
    "\n",
    "    priors = np.zeros(DEM.num_errors)\n",
    "    check_matrix = np.zeros((DEM.num_detectors, DEM.num_errors))\n",
    "    logical_matrix = np.zeros((DEM.num_observables, DEM.num_errors))\n",
    "    \n",
    "    e = 0\n",
    "    \n",
    "    for instruction in DEM.flattened():\n",
    "        \n",
    "        if instruction.type == \"error\":\n",
    "            \n",
    "            detectors: List[int] = []\n",
    "            logicals: List[int] = []\n",
    "            t: stim.DemTarget\n",
    "            p = instruction.args_copy()[0]\n",
    "            for t in instruction.targets_copy():\n",
    "                if t.is_relative_detector_id():\n",
    "                    detectors.append(t.val)\n",
    "                elif t.is_logical_observable_id():\n",
    "                    logicals.append(t.val)\n",
    "\n",
    "            priors[e] = p\n",
    "            check_matrix[detectors, e] = 1\n",
    "            logical_matrix[logicals, e] = 1\n",
    "            \n",
    "            e += 1\n",
    "            \n",
    "        elif instruction.type == \"detector\":\n",
    "            pass\n",
    "        elif instruction.type == \"logical_observable\":\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    \n",
    "    check_matrix = torch.tensor(check_matrix, dtype=torch.int)\n",
    "    logical_matrix = torch.tensor(logical_matrix, dtype=torch.int)\n",
    "    priors = torch.tensor(priors, dtype=torch.float32)\n",
    "    \n",
    "    llrs = torch.log((1 - priors) / priors)\n",
    "    \n",
    "    return DEM_Matrices(\n",
    "        check_matrix=check_matrix,\n",
    "        logical_matrix=logical_matrix,\n",
    "        llrs=llrs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nbp_decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 circuit: stim.Circuit=None,\n",
    "                 matrices: DEM_Matrices=None,\n",
    "                 layers: int = 20,\n",
    "                 batch_size: int = 1,\n",
    "                 loss_function: str = 'binary_cross_entropy',\n",
    "                 weights: str = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.layers = layers\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_fucntion = loss_function\n",
    "        \n",
    "        if circuit:\n",
    "        \n",
    "            self.circuit = circuit\n",
    "            self.dem = self.circuit.detector_error_model(decompose_errors=False)\n",
    "            \n",
    "            self.matrices = DEM_to_matrices( self.dem )\n",
    "            \n",
    "            self.H = self.matrices.check_matrix\n",
    "            self.L = self.matrices.logical_matrix\n",
    "            self.llrs = self.matrices.llrs\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.H = matrices.check_matrix\n",
    "            self.L = matrices.logical_matrix\n",
    "            self.llrs = matrices.llrs\n",
    "    \n",
    "        self.m, self.n = self.H.size()\n",
    "        \n",
    "        if not weights:\n",
    "            self.ini_weights_as_one()\n",
    "        else:\n",
    "            self.load_weights(weights)\n",
    "            \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus = nn.Softplus(beta=1.0, threshold=50)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "            \n",
    "    def ini_weights_as_one(self):\n",
    "        \n",
    "        self.weights_llr = []\n",
    "        self.weights_de = []\n",
    "        \n",
    "        self.marg_weights_llr = []\n",
    "        self.marg_weights_de = []\n",
    "        \n",
    "        self.rhos = []\n",
    "        self.residual_weights = []\n",
    "        \n",
    "        for _ in range(self.layers):\n",
    "            \n",
    "            self.weights_de.append(torch.ones_like(self.H, dtype=float, requires_grad=True, device=self.device))\n",
    "            self.weights_llr.append(torch.ones_like(self.llrs, dtype=float, requires_grad=True, device=self.device))\n",
    "            \n",
    "            self.marg_weights_de.append(torch.ones_like(self.H, dtype=float, requires_grad=True, device=self.device))\n",
    "            self.marg_weights_llr.append(torch.ones_like(self.llrs, dtype=float, requires_grad=True, device=self.device))\n",
    "        \n",
    "        self.residual_weights.append(torch.zeros(self.layers, dtype=float, requires_grad=True, device=self.device))\n",
    "        \n",
    "        self.rhos.append(torch.ones(self.layers, dtype=float, requires_grad=True, device=self.device))\n",
    "        # with torch.no_grad():\n",
    "        #     normalised_rhos = [rho / self.layers for rho in self.rhos]\n",
    "        # self.rhos = normalised_rhos\n",
    "                \n",
    "    def save_weights(self, path: str):\n",
    "    \n",
    "        file_de = 'weights_de.pt'\n",
    "        file_llr = 'weights_llr.pt'\n",
    "        \n",
    "        file_marg_de = 'marg_weights_de.pt'\n",
    "        file_marg_llr = 'marg_weights_llr.pt'\n",
    "        \n",
    "        file_residuals = 'residual_weights.pt'\n",
    "        file_rhos = 'rhos.pt'\n",
    "        \n",
    "        torch.save(self.weights_de, os.path.join(path, file_de))\n",
    "        torch.save(self.weights_llr, os.path.join(path, file_llr))\n",
    "        \n",
    "        torch.save(self.marg_weights_de, os.path.join(path, file_marg_de))\n",
    "        torch.save(self.marg_weights_llr, os.path.join(path, file_marg_llr))\n",
    "        \n",
    "        torch.save(self.residual_weights, os.path.join(path, file_residuals))\n",
    "        torch.save(self.rhos, os.path.join(path, file_rhos))\n",
    "        \n",
    "        print(f'Weigths saved at {path}.')\n",
    "        \n",
    "    def load_weights(self, path: str):\n",
    "        \n",
    "        file_de = 'weights_de.pt'\n",
    "        file_llr = 'weights_llr.pt'\n",
    "        \n",
    "        file_marg_de = 'marg_weights_de.pt'\n",
    "        file_marg_llr = 'marg_weights_llr.pt'\n",
    "        \n",
    "        file_residuals = 'residual_weights.pt'\n",
    "        file_rhos = 'rhos.pt'\n",
    "        \n",
    "        self.weights_de = torch.load(os.path.join(path, file_de)).to(self.device)\n",
    "        self.weights_llr = torch.load(os.path.join(path, file_llr)).to(self.device)\n",
    "        \n",
    "        self.marg_weights_de = torch.load(os.path.join(path, file_marg_de)).to(self.device)\n",
    "        self.marg_weights_llr = torch.load(os.path.join(path, file_marg_llr)).to(self.device)\n",
    "        \n",
    "        self.residual_weights = torch.load(os.path.join(path, file_residuals)).to(self.device)\n",
    "        self.rhos = torch.load(os.path.join(path, file_rhos)).to(self.device)\n",
    "        \n",
    "    def update_error_nodes(self, incoming_messages, weights_llr, weights_de):\n",
    "        \n",
    "        outgoing_messages = torch.zeros((self.batch_size, self.m, self.n), dtype=float, device=self.device)\n",
    "        \n",
    "        weighted_messages = incoming_messages * weights_de\n",
    "        \n",
    "        outgoing_messages += self.H * self.llrs * weights_llr\n",
    "        outgoing_messages += torch.sum(weighted_messages, dim=1, keepdim=True)\n",
    "        outgoing_messages *= self.H\n",
    "        outgoing_messages -= incoming_messages\n",
    "        \n",
    "        return outgoing_messages\n",
    "    \n",
    "    def update_detector_nodes(self, incoming_messages, syndromes):\n",
    "        \n",
    "        divider = torch.tanh(incoming_messages / 2)\n",
    "        divider = torch.where(divider == 0, torch.tensor(1.0), divider)\n",
    "        \n",
    "        multiplicator = torch.pow(-1, syndromes) * self.H\n",
    "        \n",
    "        outgoing_messages = 2*torch.atanh(torch.prod(divider, dim=2, keepdim=True) / divider)\n",
    "        outgoing_messages *= multiplicator\n",
    "        \n",
    "        return outgoing_messages\n",
    "    \n",
    "    def compute_beliefs(self, detector_to_error_messages, marg_weights_llr, marg_weights_de):\n",
    "        \n",
    "        weighted_messages = detector_to_error_messages * marg_weights_de\n",
    "        beliefs = torch.sum(weighted_messages, dim=1)\n",
    "        beliefs += self.llrs*marg_weights_llr\n",
    "        \n",
    "        return beliefs\n",
    "    \n",
    "    def infer_predictions(self, beliefs):\n",
    "        \n",
    "        predictions = torch.zeros_like(beliefs, dtype=float, device=self.device)\n",
    "        predictions[beliefs < 0] = 1\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def soft_vectors(self, beliefs):\n",
    "        return self.sigmoid(-beliefs)\n",
    "    \n",
    "    def loss(self, beliefs, errors):\n",
    "        \n",
    "        if self.loss_fucntion == 'binary_cross_entropy':\n",
    "            loss = self.softplus(beliefs)\n",
    "            loss -= (1 - errors) * beliefs\n",
    "            loss = torch.sum(loss, dim=1)\n",
    "            \n",
    "        if self.loss_fucntion == 'He=s':\n",
    "            e = errors + self.sigmoid(-beliefs)\n",
    "            loss = self.H.double() @ e.T\n",
    "            loss = torch.abs(torch.sin(np.pi * loss / 2))\n",
    "            loss = torch.sum(loss, dim=0)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def forward(self, syndromes, errors):\n",
    "        \n",
    "        rhos_normalised = self.softmax(torch.cat(self.rhos)).squeeze()\n",
    "        loss_array = torch.zeros((self.batch_size, self.layers), dtype=float, device=self.device)\n",
    "        messages_en_to_dn = torch.zeros((self.batch_size, self.m, self.n), dtype=float, device=self.device)\n",
    "        messages_dn_to_en = torch.zeros((self.batch_size, self.m, self.n), dtype=float, device=self.device)\n",
    "        \n",
    "        for i in range(self.layers):\n",
    "            \n",
    "            messages_en_to_dn = self.update_error_nodes(messages_dn_to_en, self.weights_llr[i], self.weights_de[i])\n",
    "            residual_messages = self.residual_weights[0][i] * messages_dn_to_en\n",
    "            messages_dn_to_en = self.update_detector_nodes(messages_en_to_dn, syndromes) + residual_messages\n",
    "            beliefs = self.compute_beliefs(messages_dn_to_en, self.marg_weights_llr[0], self.marg_weights_de[0])\n",
    "            loss_array[:, i] = self.loss(beliefs, errors) * rhos_normalised[i]\n",
    "\n",
    "        loss_array = loss_array\n",
    "        loss = torch.sum(loss_array, dim=1)\n",
    "        loss = torch.sum(loss, dim=0) / self.batch_size\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def decode(self, syndromes):\n",
    "        \n",
    "        messages_en_to_dn = torch.zeros((self.batch_size, self.m, self.n), dtype=float, device=self.device)\n",
    "        messages_dn_to_en = torch.zeros((self.batch_size, self.m, self.n), dtype=float, device=self.device)\n",
    "        \n",
    "        for i in range(self.layers):\n",
    "            \n",
    "            messages_en_to_dn = self.update_error_nodes(messages_dn_to_en, self.weights_llr[i], self.weights_de[i])\n",
    "            residual_messages = self.residual_weights[0][i] * messages_dn_to_en\n",
    "            messages_dn_to_en = self.update_detector_nodes(messages_en_to_dn, syndromes) + residual_messages \n",
    "            beliefs = self.compute_beliefs(messages_dn_to_en, self.marg_weights_llr[0], self.marg_weights_de[0])\n",
    "        \n",
    "        predictions = self.infer_predictions(beliefs)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def optimization_step(decoder, syndromes, errors, optimizer: torch.optim.Optimizer):\n",
    "    \n",
    "   loss = decoder.forward(syndromes, errors)\n",
    "   \n",
    "   optimizer.zero_grad()\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "   \n",
    "   return loss.detach()\n",
    "\n",
    "def training_loop(decoder, optimizer, num_batch, path):\n",
    "    \n",
    "    loss_length = num_batch\n",
    "    loss = torch.zeros(loss_length)\n",
    "\n",
    "    idx = 0\n",
    "    \n",
    "    with tqdm(total=loss_length) as pbar:\n",
    "        \n",
    "        for _ in range(num_batch):\n",
    "            \n",
    "            sampler = decoder.dem.compile_sampler()\n",
    "            syndromes, logical_flips, errors = sampler.sample(shots=10, return_errors=True)\n",
    "            \n",
    "            syndromes = torch.from_numpy(syndromes).int()\n",
    "            syndromes = torch.reshape(syndromes, (len(syndromes), len(syndromes[0]), 1))\n",
    "            logical_flips = torch.from_numpy(logical_flips).int()\n",
    "            errors = torch.from_numpy(errors).int()\n",
    "\n",
    "            loss[idx]= optimization_step(decoder, syndromes, errors, optimizer)\n",
    "            \n",
    "            pbar.update(1)\n",
    "            pbar.set_description(f\"loss {loss[idx]}\")\n",
    "            idx += 1\n",
    "            \n",
    "        decoder.save_weights(path)\n",
    "\n",
    "    print('Training completed.\\n')\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = stim.Circuit.generated(\n",
    "                \"surface_code:unrotated_memory_z\",\n",
    "                rounds=3,\n",
    "                distance=3,\n",
    "                after_clifford_depolarization=0.01,\n",
    "                after_reset_flip_probability=0.01,\n",
    "                before_measure_flip_probability=0.01,\n",
    "                before_round_data_depolarization=0.01)\n",
    "\n",
    "decoder = Nbp_decoder(circuit, loss_function='He=s', layers=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = decoder.weights_llr + decoder.weights_de + decoder.marg_weights_llr + decoder.marg_weights_de + decoder.rhos + decoder.residual_weights\n",
    "optimiser = torch.optim.Adam(parameters, lr=0.001)\n",
    "loss = training_loop(decoder, optimiser, 100, 'weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
